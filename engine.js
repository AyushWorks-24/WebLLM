async function startEngine() {
    const statusText = document.getElementById('status');
    
   
    if (!navigator.gpu) { statusText.innerText = "‚ùå No WebGPU"; return; }
    const adapter = await navigator.gpu.requestAdapter();
    const device = await adapter.requestDevice();
    
    statusText.innerHTML = `‚úÖ System Active (${adapter.info.vendor})<br>‚è≥ Downloading Model Weights...`;

   
    const modelSize = 1000; 
    const modelWeights = new Float32Array(modelSize);
    
    
    for (let i = 0; i < modelSize; i++) {
        modelWeights[i] = Math.random(); 
    }

    console.log(`üì¶ Downloaded "Model" Size: ${modelWeights.byteLength} bytes`);

    
    
    statusText.innerHTML += `<br>‚è≥ Moving Weights to GPU VRAM...`;

    
    const weightBuffer = device.createBuffer({
        size: modelWeights.byteLength, 
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST
    });

    
    device.queue.writeBuffer(weightBuffer, 0, modelWeights);

   
    const readBuffer = device.createBuffer({
        size: 4, 
        usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ
    });

    
    const commandEncoder = device.createCommandEncoder();
    commandEncoder.copyBufferToBuffer(weightBuffer, 0, readBuffer, 0, 4);
    device.queue.submit([commandEncoder.finish()]);

    await readBuffer.mapAsync(GPUMapMode.READ);
    const resultData = new Float32Array(readBuffer.getMappedRange());
    const prediction = resultData[0];

    statusText.innerHTML = `
        ‚úÖ <b>WebLLM Engine Ready!</b><br>
        ---------------------------------<br>
        üñ•Ô∏è <b>GPU:</b> ${adapter.info.vendor}<br>
        üì¶ <b>Model Loaded:</b> ${modelSize} Parameters (Simulated)<br>
        üöÄ <b>First Weight (Prediction):</b> ${prediction.toFixed(4)}
    `;
    
    console.log("Model successfully loaded into VRAM!");
}

startEngine();